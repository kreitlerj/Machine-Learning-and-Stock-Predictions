{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/addisonpietroburgo/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/core/frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n",
      "/Users/addisonpietroburgo/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/Users/addisonpietroburgo/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel/__main__.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/addisonpietroburgo/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel/__main__.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/addisonpietroburgo/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel/__main__.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import json\n",
    "import alpha_vantage\n",
    "from config import apiKey\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import keras\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.models import load_model\n",
    "from numpy import array\n",
    "\n",
    "def one_year_data(stock_ticker): \n",
    "    yesterday = datetime.strftime(datetime.now() - timedelta(1), '%Y-%m-%d')\n",
    "    past_year = datetime.strftime(datetime.now() - timedelta(366), '%Y-%m-%d')\n",
    "    \n",
    "\n",
    "    url = \"https://www.alphavantage.co/query?\"\n",
    "    query_url = f\"{url}function=TIME_SERIES_DAILY&symbol={stock_ticker}&outputsize=full&apikey={apiKey}\" \n",
    "\n",
    "    response = requests.get(query_url).json() \n",
    "\n",
    "    df = pd.DataFrame(response[\"Time Series (Daily)\"]) \n",
    "\n",
    "    df_transposed = df.T # or df1.transpose()\n",
    "\n",
    "    df_filtered = df_transposed[yesterday : past_year] \n",
    "\n",
    "    df_filtered.rename(columns={'4. close':'close', '3. low':'low', '2. high':'high', '5. volume':'volume'}, inplace=True)\n",
    "    \n",
    "    df_filtered.drop('1. open', axis=1, inplace=True)\n",
    "    \n",
    "    df_filtered = df_filtered[[\"close\", \"low\", \"high\", \"volume\"]]\n",
    "    \n",
    "    df_filtered.close = pd.to_numeric(df_filtered.close, errors='coerce')\n",
    "    df_filtered.low = pd.to_numeric(df_filtered.low, errors='coerce')\n",
    "    df_filtered.high = pd.to_numeric(df_filtered.high, errors='coerce')\n",
    "    df_filtered.volume = pd.to_numeric(df_filtered.volume, errors='coerce')\n",
    "    df_filtered.index = pd.to_datetime(df_filtered.index)\n",
    "    df_filtered = df_filtered.sort_index(ascending=True)\n",
    "    \n",
    "    ten_day_model = load_model(\"ML/model_ten_day.h5\")\n",
    "    thirty_day_model = load_model(\"ML/model_thirty_day.h5\")\n",
    "    sixty_day_model = load_model(\"ML/model_sixty_day.h5\")    \n",
    "    \n",
    "    #sixty day model\n",
    "    dataset = df_filtered.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "    X_test, y_test = [], []\n",
    "    for i in range(61,len(dataset)):\n",
    "        X_test.append(scaled_data[i-61:i-1,0:4])\n",
    "        y_test.append(scaled_data[i,0])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    closing_price = sixty_day_model.predict(X_test)\n",
    "    \n",
    "    final = []\n",
    "    for price in closing_price:\n",
    "        final.append(np.pad(price, (0, 3), 'constant'))\n",
    "    final_price = scaler.inverse_transform(final)\n",
    "    close = []\n",
    "    for price in final_price:\n",
    "        close.append(price[0])\n",
    "    \n",
    "    valid_sixty_day = df_filtered[61:] \n",
    "    valid_sixty_day[\"predictions\"] = close\n",
    "    \n",
    "    #thirty day model \n",
    "    dataset = df_filtered.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "    X_test, y_test = [], []\n",
    "    for i in range(31,len(dataset)):\n",
    "        X_test.append(scaled_data[i-31:i-1,0:4])\n",
    "        y_test.append(scaled_data[i,0])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    closing_price = thirty_day_model.predict(X_test)\n",
    "    \n",
    "    final = []\n",
    "    for price in closing_price:\n",
    "        final.append(np.pad(price, (0, 3), 'constant'))\n",
    "    final_price = scaler.inverse_transform(final)\n",
    "    close = []\n",
    "    for price in final_price:\n",
    "        close.append(price[0])\n",
    "    \n",
    "    valid_thirty_day = df_filtered[31:] \n",
    "    valid_thirty_day[\"predictions\"] = close\n",
    "    \n",
    "    #ten day model\n",
    "    dataset = df_filtered.values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(dataset)\n",
    "    X_test, y_test = [], []\n",
    "    for i in range(11,len(dataset)):\n",
    "        X_test.append(scaled_data[i-11:i-1,0:4])\n",
    "        y_test.append(scaled_data[i,0])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    closing_price = ten_day_model.predict(X_test)\n",
    "    \n",
    "    final = []\n",
    "    for price in closing_price:\n",
    "        final.append(np.pad(price, (0, 3), 'constant'))\n",
    "    final_price = scaler.inverse_transform(final)\n",
    "    close = []\n",
    "    for price in final_price:\n",
    "        close.append(price[0])\n",
    "    \n",
    "    valid_ten_day = df_filtered[11:]  \n",
    "    valid_ten_day[\"predictions\"] = close\n",
    "    \n",
    "    #output to json\n",
    "    valid_sixty_day = valid_sixty_day[-90:]\n",
    "    valid_thirty_day = valid_thirty_day[-90:]\n",
    "    valid_ten_day = valid_ten_day[-90:]  \n",
    "    \n",
    "    valid_sixty_day = valid_sixty_day.to_json(orient='index') \n",
    "    valid_thirty_day = valid_thirty_day.to_json(orient='index')\n",
    "    valid_ten_day = valid_ten_day.to_json(orient='index')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return valid_sixty_day, valid_thirty_day, valid_ten_day\n",
    "     \n",
    "    \n",
    "\n",
    "sixty, thirty, ten = one_year_data(\"GOOG\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sixty = sixty[-90:]\n",
    "#thirty = thirty[-90:]\n",
    "#ten = ten[-90:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.figure(figsize=(16,8))\n",
    "#plt.plot(sixty[['close', 'predictions']])\n",
    "#plt.plot(thirty[['predictions']]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sixty_json = sixty.to_json(orient='index') \n",
    "#thirty_json = thirty.to_json(orient='index')\n",
    "#ten_json = ten.to_json(orient='index')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
